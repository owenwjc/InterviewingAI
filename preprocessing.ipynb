{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oclinton/miniconda3/envs/venv/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-05-13 20:46:18.816439: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-13 20:46:19.337042: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-05-13 20:46:19.337103: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-05-13 20:46:19.337108: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import textstat\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from transformers import pipeline\n",
    "# from nltk.sentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_kwargs = {'padding':True,'truncation':True,'max_length':512}\n",
    "classifier = pipeline(\"text-classification\", model=\"j-hartmann/emotion-english-distilroberta-base\", device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vocabulary(text):\n",
    "    vectorizer = CountVectorizer()\n",
    "    model = vectorizer.fit_transform([text])\n",
    "    terms = vectorizer.get_feature_names_out()\n",
    "    return len(terms)\n",
    "\n",
    "def get_vocab_counter(text):\n",
    "    vectorizer = CountVectorizer()\n",
    "    model = vectorizer.fit_transform([text])\n",
    "    terms = vectorizer.get_feature_names_out()\n",
    "    return Counter(terms)\n",
    "\n",
    "def get_n_grams(text, numgram):\n",
    "    vectorizer = CountVectorizer(lowercase=False,token_pattern = '[a-zA-Z0-9|\\']+', analyzer='word', ngram_range=(numgram, numgram))\n",
    "    model = vectorizer.fit_transform([text])\n",
    "    terms = vectorizer.get_feature_names_out()\n",
    "    scores = model.toarray().flatten().tolist()\n",
    "    data = list(zip(terms,scores))\n",
    "    sorted_data = sorted(data, key=lambda x: x[1],reverse=True)\n",
    "    return sorted_data[0][0]\n",
    "\n",
    "def get_word_cloud(text):\n",
    "    vectorizer = CountVectorizer(stop_words='english')\n",
    "    model = vectorizer.fit_transform([text])\n",
    "    terms = vectorizer.get_feature_names_out()\n",
    "    scores = model.toarray().flatten().tolist()\n",
    "    data = list(zip(terms,scores))\n",
    "    sorted_data = sorted(data, key=lambda x: x[1],reverse=True)\n",
    "    return dict(sorted_data[:20])\n",
    "\n",
    "def get_emotion(text):\n",
    "    result = classifier(text, **tokenizer_kwargs)[0]\n",
    "    return result['label']\n",
    "\n",
    "# def get_sentiment(text):\n",
    "#     sia = SentimentIntensityAnalyzer()\n",
    "#     return sia.polarity_scores(text)['compound']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oclinton/miniconda3/envs/venv/lib/python3.8/site-packages/transformers/pipelines/base.py:1045: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# import and transform raw data to pivot answers into single column\n",
    "df = pd.read_excel('data/data.xlsx')\n",
    "df = df.rename({'ans1': 1, 'ans2': 2, 'ans3': 3}, axis=1)\n",
    "df = pd.melt(df, id_vars=['model', 'type', 'question'], value_vars=[1, 2, 3])\n",
    "df = df.rename({'variable': 'run', 'value': 'text'}, axis=1)\n",
    "\n",
    "# define dataset subsets from raw data by grouping and combining text strings\n",
    "overall = df.groupby(['model', 'run'])['text'].apply(lambda x: '. '.join(x)).reset_index()\n",
    "agg_overall = df.groupby(['model'])['text'].apply(lambda x: '. '.join(x)).reset_index()\n",
    "categories = df.groupby(['model', 'type', 'run'])['text'].apply(lambda x: '. '.join(x)).reset_index()\n",
    "agg_categories = df.groupby(['model', 'type'])['text'].apply(lambda x: '. '.join(x)).reset_index()\n",
    "questions = df.copy()\n",
    "agg_questions = df.groupby(['model', 'type', 'question'])['text'].apply(lambda x: '. '.join(x)).reset_index()\n",
    "\n",
    "# get flesch kincaid grade level for each answer or group of answers\n",
    "overall['readibility'] = overall.apply(lambda x: textstat.flesch_kincaid_grade(x['text']), axis=1)\n",
    "agg_overall['readibility'] = agg_overall.apply(lambda x: textstat.flesch_kincaid_grade(x['text']), axis=1)\n",
    "categories['readibility'] = categories.apply(lambda x: textstat.flesch_kincaid_grade(x['text']), axis=1)\n",
    "agg_categories['readibility'] = agg_categories.apply(lambda x: textstat.flesch_kincaid_grade(x['text']), axis=1)\n",
    "questions['readibility'] = questions.apply(lambda x: textstat.flesch_kincaid_grade(x['text']), axis=1)\n",
    "agg_questions['readibility'] = agg_questions.apply(lambda x: textstat.flesch_kincaid_grade(x['text']), axis=1)\n",
    "\n",
    "# get word count for each answer then get mean of answer length for each grouping\n",
    "questions['word_count'] = questions.apply(lambda x: textstat.lexicon_count(x['text']), axis=1)\n",
    "overall['word_count'] = questions.groupby(['model', 'run'])['word_count'].mean().reset_index()['word_count']\n",
    "agg_overall['word_count'] = questions.groupby(['model'])['word_count'].mean().reset_index()['word_count']\n",
    "categories['word_count'] = questions.groupby(['model','type', 'run'])['word_count'].mean().reset_index()['word_count']\n",
    "agg_categories['word_count'] = questions.groupby(['model','type'])['word_count'].mean().reset_index()['word_count']\n",
    "agg_questions['word_count'] = questions.groupby(['model', 'type', 'question'])['word_count'].mean().reset_index()['word_count']\n",
    "\n",
    "# get vocabulary size for each answer or grouping of answers\n",
    "overall['vocab'] = overall['text'].apply(lambda x: get_vocabulary(x))\n",
    "agg_overall['vocab'] = agg_overall['text'].apply(lambda x: get_vocabulary(x))\n",
    "categories['vocab'] = categories['text'].apply(lambda x: get_vocabulary(x))\n",
    "agg_categories['vocab'] = agg_categories['text'].apply(lambda x: get_vocabulary(x))\n",
    "questions['vocab'] = questions['text'].apply(lambda x: get_vocabulary(x))\n",
    "agg_questions['vocab'] = agg_questions['text'].apply(lambda x: get_vocabulary(x))\n",
    "\n",
    "# get each run's unique vocabulary count\n",
    "overall['vocab_count'] = overall['text'].apply(lambda x: get_vocab_counter(x))\n",
    "categories['vocab_count'] = categories['text'].apply(lambda x: get_vocab_counter(x))\n",
    "questions['vocab_count'] = questions['text'].apply(lambda x: get_vocab_counter(x))\n",
    "\n",
    "overall['total'] = pd.merge(overall, overall.groupby(['model'])['vocab_count'].sum().reset_index(), on='model')['vocab_count_y']\n",
    "overall['diff'] = overall['total'] - overall['vocab_count']\n",
    "overall['unique_vocab'] = overall.apply(lambda x: len(set(x['total']).difference(set(x['diff']))), axis=1)\n",
    "overall.drop(columns=['vocab_count', 'total', 'diff'], inplace=True)\n",
    "\n",
    "categories['total'] = pd.merge(categories, categories.groupby(['model', 'type'])['vocab_count'].sum().reset_index(), on='model')['vocab_count_y']\n",
    "categories['diff'] = categories['total'] - categories['vocab_count']\n",
    "categories['unique_vocab'] = categories.apply(lambda x: len(set(x['total']).difference(set(x['diff']))), axis=1)\n",
    "categories.drop(columns=['vocab_count', 'total', 'diff'], inplace=True)\n",
    "\n",
    "questions['total'] = pd.merge(questions, questions.groupby(['model', 'type', 'question'])['vocab_count'].sum().reset_index(), on='model')['vocab_count_y']\n",
    "questions['diff'] = questions['total'] - questions['vocab_count']\n",
    "questions['unique_vocab'] = questions.apply(lambda x: len(set(x['total']).difference(set(x['diff']))), axis=1)\n",
    "questions.drop(columns=['vocab_count', 'total', 'diff'], inplace=True)\n",
    "\n",
    "# get most common ngram for aggregated answers\n",
    "agg_overall['ngram'] = agg_overall['text'].apply(lambda x: get_n_grams(x, 8))\n",
    "agg_categories['ngram'] = agg_categories['text'].apply(lambda x: get_n_grams(x, 6))\n",
    "agg_questions['ngram'] = agg_questions['text'].apply(lambda x: get_n_grams(x, 4))\n",
    "\n",
    "# get set of most common words for aggregated answers\n",
    "agg_overall['word_cloud'] = agg_overall['text'].apply(lambda x: get_word_cloud(x))\n",
    "agg_categories['word_cloud'] = agg_categories['text'].apply(lambda x: get_word_cloud(x))\n",
    "agg_questions['word_cloud'] = agg_questions['text'].apply(lambda x: get_word_cloud(x))\n",
    "\n",
    "# get emotion of each answer\n",
    "questions['emotion'] = questions['text'].apply(lambda x: get_emotion(x))\n",
    "\n",
    "# drop text column\n",
    "questions.drop(columns=['text'],inplace=True)\n",
    "agg_questions.drop(columns=['text'],inplace=True)\n",
    "categories.drop(columns=['text'],inplace=True)\n",
    "agg_categories.drop(columns=['text'],inplace=True)\n",
    "overall.drop(columns=['text'],inplace=True)\n",
    "agg_overall.drop(columns=['text'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output to csv\n",
    "questions.to_csv('data/questions.csv', index=False)\n",
    "agg_questions.to_csv('data/agg_questions.csv', index=False)\n",
    "categories.to_csv('data/categories.csv', index=False)\n",
    "agg_categories.to_csv('data/agg_categories.csv', index=False)\n",
    "overall.to_csv('data/overall.csv', index=False)\n",
    "agg_overall.to_csv('data/agg_overall.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
